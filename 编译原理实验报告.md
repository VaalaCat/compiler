# 编译原理实验报告

## 实验一

### 设计方案

#### 功能模块结构图

词法分析器程序文件为 `lex.py`，其有以下模块，蓝色为全局变量，黄色为主要功能函数

![](assets/lexstruct.svg)

#### 主体结构流程图

对于词法分析器，主要功能是读入源代码字符串流，输出 Token 流和符号表。其中 `lexer` 函数是主要程序，其结构为

![](assets/lexer.svg)

对于其调用的函数，依赖图为：

![](assets/lexer3.svg)

#### 主要数据结构

- 符号表，在扫描的同时生成并维护，示例代码的符号表如下
```json
{'addr': '0', 'value': 'a', 'type': 'id', 'line': 1, 'cur': 7}
{'addr': '1', 'value': 'b', 'type': 'id', 'line': 2, 'cur': 7}
{'addr': '2', 'value': 'c', 'type': 'id', 'line': 3, 'cur': 7}
{'addr': '3', 'value': '2', 'type': 'digits', 'line': 4, 'cur': 7}
{'addr': '4', 'value': '1', 'type': 'digits', 'line': 5, 'cur': 7}
```
- Token串，边识别边维护，示例代码部分 Token 串如下，其中保留行和光标位置用于报错和警告提示
```json
["Keyword", "int", {"line": 1, "cur": 5}]
["id", "0", {"line": 1, "cur": 7}]
["OP", ";", {"line": 2, "cur": 1}]
["Keyword", "int", {"line": 2, "cur": 5}]
["id", "1", {"line": 2, "cur": 7}]
["OP", ";", {"line": 3, "cur": 1}]
["Keyword", "int", {"line": 3, "cur": 5}]
["id", "2", {"line": 3, "cur": 7}]
["OP", ";", {"line": 4, "cur": 1}]
["id", "0", {"line": 4, "cur": 3}]
["OP", "=", {"line": 4, "cur": 5}]
["digits", "3", {"line": 4, "cur": 7}]
["OP", ";", {"line": 5, "cur": 1}]
["id", "1", {"line": 5, "cur": 3}]
```

#### 开发平台

- Python 3.9.8 on Darwin arm64
```
Python 3.9.8 (main, Nov 10 2021, 03:48:35)
[Clang 13.0.0 (clang-1300.0.29.3)] on darwin for arm
```

- 额外依赖包：无

### 具体实现

- `read`
对于词法分析器首先需要扫描源文件到缓冲区，可以使用直接从标准输入输出
```py
def read(**kwargs):
    content = ""
    if "mode" in kwargs and kwargs["mode"] == 'file':
        if "filepath" in kwargs and kwargs["filepath"] is None:
            print("Error:", "Empty File Path.")
            return False
        try:
            f = open(kwargs["filepath"])
        except:
            print("Error:", "Open file failed, please confirm your filepath is right.")
            return False

        content = f.read()
    else:
        print("Please input your code HERE ,press 'EOF' and ENTER to end your input!")
        print(">>> ", end="")
        tmp = ""
        while tmp != "EOF":
            tmp = input()
            print(">>> ", end="")
            if tmp != "EOF":
                content += tmp+"\n"
        print("")
    return content
```

- 辅助判断函数
```
isLetter 	# 判断某个符号是否为 Letter
isNumber	# 判断某个符号是否为 Number
lookup		# 查询符号是否在符号表中存在
isKeyword	# 判断某符号是否为关键字
isSpacer	# 判断某符号是否为空，可省略
maybeOP		# 判断某符号是否可能为操作符 (双字操作符)
```

- 错误和警告处理

错误处理：当发生错误时调用该函数，该函数会接受当前光标所在位置和错误信息，将错误显示给用户，并且会请求用户如何处理该错误信息，如果用户选择跳过，则会启动恐慌模式，删除掉错误信息尝试恢复

```python
def lexErrMsg(cur=0, line=0, content=""):
    global errCnt
    errCnt += 1
    spaceser()
    print(
        f"Error {errCnt}:", f"there's a error at line {line} cur {cur} which is:")

    print(content)
    print("Please check your code, ignore it and continue? (Y/N): ", end="")
    while True:
        opt = input("")
        if opt == "Y":
            print("Ignore this error, continue process...")
            spaceser()
            return True
        elif opt == "N":
            print("Error, Exit process...")
            spaceser()
            return False
        else:
            print("Please input Y/N:", end="")
```

警告处理：当用户未按要求严格输入但可能不对编译结果造成影响时词法分析器会使用该函数提醒用户，并指出错误位置，但不会打断编译流程，会继续处理直到编译完成

```python
def lexWarning(cur=0, line=0, content=""):
    global warCnt
    warCnt += 1
    spaceser()
    print(f"Warning {warCnt}:",
          f"There's a warning at line {line} cur {cur} which is:")
    print(content)
    print("Vaala's Lexer try to continue, the ans may be not right, check your code.")
    spaceser()
```

- `lexer`

该实验的主要工作是由该函数负责，该函数接受源代码输入，输出 token 和 符号表，工作流程为：
```python
def lexer(sourceCode):
	# 1. 添加结束符
	# 2. 识别关键词
	# 3. 识别符号
	# 4. 识别id
	# 5. 识别digits
```
除关键词识别使用直接匹配外，其它文法符号的识别均使用自动机完成，下面给出自动机状态图：

- id
![](assets/latm.svg)
- digits
![](assets/datm.svg)

具体实现流程参见主干代码
```python
def lexer(sourceCode):
    # 添加结束符
    sourceCode += "$"
    finalTokens = []
    symbols = []
    previousLetters = ""
    # cnt,line用于错误提示定位
    cnt = 1
    line = 1
    for i in sourceCode:
        cnt += 1
        if i == "\n":
            line += 1
            cnt = 1
        # 关键词是最优先的
        if isKeyword(previousLetters):
            finalTokens.append(["Keyword", previousLetters,
                               {"line": line, "cur": cnt}])
            previousLetters = ""
        # 首先是OP,先处理单个无后继符号
        if previousLetters == "":
            # 读到这几个符号那一定是独立符号，直接存
            if i == "+" or i == "-" or i == "*" or i == "/" or i == ";" or i == "(" or i == ")" or i == "'":
                finalTokens.append(["OP", i, {"line": line, "cur": cnt}])
                continue
            # 这几个符号可能有后继，需要先存着给后面
            elif i == "<" or i == "=" or i == ">" or i == "!":
                previousLetters += i
                continue
        # 然后处理可能有后续的符号
        elif previousLetters == "<" or previousLetters == "=" or previousLetters == "<" or previousLetters == "!":
            # 如果是等号那组合起来就是OP
            if i == "=":
                previousLetters += i
                finalTokens.append(
                    ["OP", previousLetters, {"line": line, "cur": cnt}])
                previousLetters = ""
                continue
            # 后面是空格或者字符/数字，就存了
            elif isSpacer(i) or isLetter(i) or isNumber(i):
                finalTokens.append(
                    ["OP", previousLetters, {"line": line, "cur": cnt}])
                if not isSpacer(i):
                    previousLetters = i
                else:
                    previousLetters = ""
                continue
            # 如果后面不是等号或者合法的跟随字，那就报错并询问要不要跳过它继续处理
            else:
                # 如果选择跳过，那就清空记录，并且下一个词
                if lexErrMsg(cnt, line, previousLetters):
                    previousLetters = ""
                    continue
                # 如果选择不跳过，那就错误退出
                else:
                    exit(1)
        # 最后处理前面传来的OP
        elif maybeOP(previousLetters):
            finalTokens.append(
                ["OP", previousLetters, {"line": line, "cur": cnt}])
            if not isSpacer(i):
                previousLetters = i
            else:
                previousLetters = ""
            continue
        # 到这里OP就处理完了，接下来处理id
        # id是单个letter或letter组合
        # 如果刚开始读就直接开始处理
        if previousLetters == "":
            # 读到字母就继续
            if isLetter(i):
                previousLetters += i
                continue
        # 只需要检测前一个符号是不是字母
        elif isLetter(previousLetters[-1]):
            if isLetter(i):
                previousLetters += i
                continue
            # 读到空格或符号代表终结
            elif isSpacer(i) or maybeOP(i):
                # 如果没填过这个符号
                idx = lookup(symbols, previousLetters)
                if idx == -1:
                    addr = len(symbols)
                    symbols.append(
                        {"addr": str(addr), "value": previousLetters, "type": "id", "line": line, "cur": cnt})
                    idx = addr
                finalTokens.append(
                    ["id", str(idx), {"line": line, "cur": cnt}])
                if maybeOP(i):
                    previousLetters = i
                else:
                    previousLetters = ""
                continue
            # 读到其它东西先报个Warning然后存token
            else:
                lexWarning(cnt, line, previousLetters+i)
                idx = lookup(symbols, previousLetters)
                if idx == -1:
                    addr = len(symbols)
                    symbols.append(
                        {"addr": str(addr), "value": previousLetters, "type": "id", "line": line, "cur": cnt})
                    idx = addr
                finalTokens.append(
                    ["id", str(idx), {"line": line, "cur": cnt}])
                previousLetters = i
                continue
        # id处理完过后我们来处理digits
        # 首先处理缓冲区没东西的情况
        if previousLetters == "":
            if isNumber(i):
                previousLetters += i
                continue
        # 只需要判断前一个符号是不是数字
        elif isNumber(previousLetters[-1]):
            # 如果当前符号是数字那就继续
            if isNumber(i):
                previousLetters += i
                continue
            # 如果是空格或者符号那就存
            elif isSpacer(i) or maybeOP(i):
                addr = len(symbols)
                symbols.append(
                    {"addr": str(addr), "value": previousLetters, "type": "digits", "line": line, "cur": cnt})
                finalTokens.append(
                    ["digits", str(addr), {"line": line, "cur": cnt}])
                if maybeOP(i):
                    previousLetters = i
                else:
                    previousLetters = ""
                continue
            # 如果读到其它东西报Warning然后存
            else:
                lexWarning(cnt, line, previousLetters+i)
                addr = len(symbols)
                symbols.append(
                    {"addr": str(addr), "value": previousLetters, "type": "digits", "line": line, "cur": cnt})
                finalTokens.append(
                    ["digits", str(addr), {"line": line, "cur": cnt}])
                previousLetters = i
                continue
    return [finalTokens, symbols]
```

### 总结反思

本次试验使用 python 并且没有调用第三方依赖实现了一个小型简单的词法分析器，让我体会到了形式语言和编译原理的深奥，激发了我对计算机科学的兴趣，由于实验一较为基础简单，并没有碰到特别的问题。

## 实验二

### 设计方案

#### 功能模块结构图

对于语法分析器，需要